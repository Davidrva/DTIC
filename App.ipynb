{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80470ee2-2b4f-4af4-9eca-85c75fb402f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [14/Jan/2025 22:48:30] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from flask import Flask, request, jsonify\n",
    "import nest_asyncio\n",
    " \n",
    "# Permitir múltiples bucles de eventos en Jupyter\n",
    "nest_asyncio.apply()\n",
    " \n",
    "# Crear la aplicación Flask\n",
    "app = Flask(__name__)\n",
    " \n",
    "# URL del modelo servido por MLflow, configurable a través de variables de entorno\n",
    "MODEL_URL = os.getenv(\"RegresionLineal\", \"http://127.0.0.1:5001/invocations\")\n",
    " \n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    \"\"\"Endpoint de prueba para verificar que la API está en funcionamiento.\"\"\"\n",
    "    return jsonify({\"message\": \"Flask está funcionando y listo para recibir predicciones.\"})\n",
    " \n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    \"\"\"Endpoint para realizar predicciones enviando datos al modelo servido en MLflow.\"\"\"\n",
    "    try:\n",
    "        # Leer datos del cuerpo de la solicitud\n",
    "        data = request.get_json()\n",
    "        if not data or \"instances\" not in data:\n",
    "            return jsonify({\"error\": \"Solicitud inválida, falta 'instances'.\"}), 400\n",
    " \n",
    "        # Enviar datos al modelo desplegado en MLflow\n",
    "        response = requests.post(MODEL_URL, json=data)\n",
    "        response.raise_for_status()  # Verificar si hubo algún error en la solicitud\n",
    "        predictions = response.json()\n",
    "        return jsonify({\"predictions\": predictions})\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return jsonify({\"error\": f\"Error al conectarse con el modelo en {MODEL_URL}: {str(e)}\"}), 500\n",
    " \n",
    "# Ejecutar el servidor Flask en Jupyter Notebook\n",
    "if __name__ == \"__main__\":\n",
    "    from werkzeug.serving import run_simple\n",
    "run_simple(\"127.0.0.1\", 8000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb30d0-be15-41c6-bc10-96c696e3bb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (envname)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
